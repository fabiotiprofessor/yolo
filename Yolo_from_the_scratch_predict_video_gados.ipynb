{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiotiprofessor/yolo/blob/main/Yolo_from_the_scratch_predict_video_gados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duPLcCU-5JKZ",
        "outputId": "a6c0ffc0-5f1c-4c45-97aa-62a5516be1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY-n51iHEM_t",
        "outputId": "0d871e49-0899-4d82-ea2a-283e35538029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.93-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/41.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.6-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.93-py3-none-any.whl (871 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m871.6/871.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.6-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.2.93 ultralytics-thop-2.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EOeLFZGTo-xf",
        "outputId": "68246b31-fb6b-4e7f-e308-f82ca177d712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.92 üöÄ Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8m summary (fused): 218 layers, 25,886,080 parameters, 0 gradients, 78.9 GFLOPs\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 830, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 567, in predict\n",
            "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 183, in predict_cli\n",
            "    for _ in gen:  # sourcery skip: remove-empty-nested-block, noqa\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 36, in generator_context\n",
            "    response = gen.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 226, in stream_inference\n",
            "    self.setup_source(source if source is not None else self.args.source)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 198, in setup_source\n",
            "    self.dataset = load_inference_source(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\", line 202, in load_inference_source\n",
            "    dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\", line 292, in __init__\n",
            "    raise FileNotFoundError(f\"{p} does not exist\")\n",
            "FileNotFoundError: /content/drive/MyDrive/Videos_Gados/Basal/basal_22.mp4 does not exist\n"
          ]
        }
      ],
      "source": [
        "!yolo detect predict model=yolov8m.pt source=\"/content/drive/MyDrive/Videos_Gados/Basal/basal_22.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find \"/content/drive/MyDrive/Videos_Gados/Basal\" -type f -name \"*.mp4\""
      ],
      "metadata": {
        "id": "pyR-eahJ4r54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "\n",
        "\n",
        "# Check if the directory exists, and create it if it doesn't\n",
        "directory_path = \"/content/drive/MyDrive/Videos_Gados/Basal\"\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "\n",
        "for video in [f for f in os.listdir(directory_path) if f.endswith(\".mp4\")]:\n",
        "  video_path = os.path.join(directory_path, video)\n",
        "  subprocess.run([\"yolo\", \"detect\", \"predict\", \"model=yolov8m.pt\", f\"source={video_path}\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIIDIcXW5BAQ",
        "outputId": "f888eece-e51f-4984-96fb-a8d46fae5fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqmhGYafF5Xt"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjU7Uwx2HJL1",
        "outputId": "1ac444ea-c888-441a-f897-f1f626f0f318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 119MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOqXJHMLNHuu"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import IPython\n",
        "IPython.get_ipython().run_line_magic('config', \"IPKernelApp.text_handler='utf8'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rxCcQd6HrcV"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import IPython\n",
        "IPython.get_ipython().run_line_magic('config', \"IPKernelApp.text_handler='utf8'\")\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "class YOLOModel:\n",
        "    def __init__(self):\n",
        "        self.model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "    def detect_animals(self, frame):\n",
        "        results = self.model.predict(frame)\n",
        "        animals = []\n",
        "        for result in results:\n",
        "            for item in result.boxes:\n",
        "                x1, y1, x2, y2 = [int(c) for c in item.xyxy[0]]\n",
        "                animal = {\n",
        "                    'box': [x1, y1, x2, y2],\n",
        "                    'class': int(item.cls[0]),\n",
        "                    'confidence': float(item.conf[0])\n",
        "                }\n",
        "                animals.append(animal)\n",
        "        return animals\n",
        "\n",
        "    def classify_animal(self, animals):\n",
        "      if animals:\n",
        "        main_animal = max(animals, key=lambda x: x['confidence'])\n",
        "        if main_animal['class'] == 0:\n",
        "          return 'dor'\n",
        "        else:\n",
        "          return 'n√£o dor'\n",
        "      else:\n",
        "        return 'Nenhum animal detectado'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Diret√≥rio dos v√≠deos\n",
        "video_dir = \"/content/drive/MyDrive/Videos_Gados/Basal\"\n",
        "\n",
        "# Carrega o modelo YOLO\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "# Dura√ß√£o da captura em segundos\n",
        "duration = 5\n",
        "\n",
        "for filename in os.listdir(video_dir):\n",
        "  if filename.endswith(\".mp4\"):\n",
        "    video_path = os.path.join(video_dir, filename)\n",
        "\n",
        "    # Abre o v√≠deo\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Obt√©m o FPS do v√≠deo\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Calcula o n√∫mero de frames para a dura√ß√£o desejada\n",
        "    num_frames = int(duration * fps)\n",
        "\n",
        "    # Loop para capturar frames do v√≠deo\n",
        "    for i in range(num_frames):\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "\n",
        "      # Realiza a detec√ß√£o de objetos\n",
        "      results = model(frame)\n",
        "\n",
        "      # Desenha as bounding boxes e labels na imagem\n",
        "      annotated_frame = results[0].plot()\n",
        "\n",
        "      # Exibe o frame com as bounding boxes\n",
        "      cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
        "\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_2Hv-7o5jhX",
        "outputId": "89217b52-583e-41c7-f47d-3746fac5dbc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.92)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.7M/49.7M [00:00<00:00, 204MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Diret√≥rio dos v√≠deos\n",
        "video_dir = \"/content/drive/MyDrive/Videos_Gados/Basal\"\n",
        "\n",
        "# Carrega o modelo YOLO\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "# Dura√ß√£o da captura em segundos\n",
        "duration = 5\n",
        "\n",
        "# Fun√ß√£o hipot√©tica para classificar a dor (substitua por sua l√≥gica)\n",
        "def classificar_dor(frame):\n",
        "  # ... (l√≥gica para extrair caracter√≠sticas e classificar a dor) ...\n",
        "  # Retorna um valor de dor (exemplo: 0.0 - 1.0)\n",
        "  # Substitua este valor por sua l√≥gica de classifica√ß√£o de dor\n",
        "  valor_dor = 0.8\n",
        "  return valor_dor\n",
        "\n",
        "\n",
        "for filename in os.listdir(video_dir):\n",
        "  if filename.endswith(\".mp4\"):\n",
        "    video_path = os.path.join(video_dir, filename)\n",
        "\n",
        "    # Abre o v√≠deo\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Obt√©m o FPS do v√≠deo\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Calcula o n√∫mero de frames para a dura√ß√£o desejada\n",
        "    num_frames = int(duration * fps)\n",
        "\n",
        "    # Loop para capturar frames do v√≠deo\n",
        "    for i in range(num_frames):\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "\n",
        "      # Realiza a detec√ß√£o de objetos\n",
        "      results = model(frame)\n",
        "\n",
        "      # Loop sobre as detec√ß√µes\n",
        "      for r in results:\n",
        "        boxes = r.boxes\n",
        "        for box in boxes:\n",
        "          # Obt√©m as coordenadas da bounding box\n",
        "          x1, y1, x2, y2 = box.xyxy[0].int()\n",
        "\n",
        "          # Recorta o frame usando as coordenadas da bounding box\n",
        "          cropped_frame = frame[y1:y2, x1:x2]\n",
        "\n",
        "          # Classifica a dor usando o frame recortado\n",
        "          valor_dor = classificar_dor(cropped_frame)\n",
        "\n",
        "          # Adiciona o valor da dor ao frame original\n",
        "          cv2_putText(frame, f\"Dor: {valor_dor:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "      # Exibe o frame com as bounding boxes e valores de dor\n",
        "      cv2_imshow(\"YOLOv8 Inference\", frame)\n",
        "\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buIxlnHW_-Ff",
        "outputId": "6e708790-4899-4d56-c047-9d634bbd5a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.92)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Diret√≥rio dos v√≠deos\n",
        "video_dir = \"/content/drive/MyDrive/Videos_Gados/Basal\"\n",
        "\n",
        "# Carrega o modelo YOLO\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "# Dura√ß√£o da captura em segundos\n",
        "duration = 5\n",
        "\n",
        "# Fun√ß√£o hipot√©tica para classificar a dor (substitua por sua l√≥gica)\n",
        "def classificar_dor(frame):\n",
        "  # ... (l√≥gica para extrair caracter√≠sticas e classificar a dor) ...\n",
        "  # Retorna um valor de dor (exemplo: 0.0 - 1.0)\n",
        "  # Substitua este valor por sua l√≥gica de classifica√ß√£o de dor\n",
        "  valor_dor = 0.8\n",
        "  return valor_dor\n",
        "\n",
        "for filename in os.listdir(video_dir):\n",
        "  if filename.endswith(\".mp4\"):\n",
        "    video_path = os.path.join(video_dir, filename)\n",
        "\n",
        "    # Abre o v√≠deo\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Obt√©m o FPS do v√≠deo\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Calcula o n√∫mero de frames para a dura√ß√£o desejada\n",
        "    num_frames = int(duration * fps)\n",
        "\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "\n",
        "      # Realiza a detec√ß√£o de objetos\n",
        "      results = model(frame, conf=0.25)\n",
        "\n",
        "      # Loop sobre as detec√ß√µes\n",
        "      for r in results:\n",
        "        boxes = r.boxes\n",
        "        for box in boxes:\n",
        "          # Obt√©m as coordenadas da bounding box\n",
        "          x1, y1, x2, y2 = box.xyxy[0].int()\n",
        "\n",
        "          # Recorta o frame usando as coordenadas da bounding box\n",
        "          cropped_frame = frame[y1:y2, x1:x2]\n",
        "\n",
        "          # Classifica a dor usando o frame recortado\n",
        "          valor_dor = classificar_dor(cropped_frame)\n",
        "\n",
        "          # Adiciona o valor da dor ao frame original\n",
        "          cv2.putText(frame, f\"Dor: {valor_dor:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "      # Exibe o frame com as bounding boxes e valores de dor\n",
        "      cv2.imshow(\"YOLOv8 Inference\", frame)\n",
        "\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Fr_xC9lcyI6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo model download yolov8n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPdpuRUSd2Mt",
        "outputId": "5febcaf3-5bc6-4ce4-f5ea-25fc0a96cd0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 755, in entrypoint\n",
            "    raise SyntaxError(\n",
            "SyntaxError: '\u001b[31m\u001b[1mmodel\u001b[0m' is a valid YOLO argument but is missing an '=' sign to set its value, i.e. try 'model=None'\n",
            "\n",
            "    Arguments received: ['yolo', 'model', 'download', 'yolov8n']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of {'segment', 'classify', 'pose', 'detect', 'obb'}\n",
            "                MODE (required) is one of {'predict', 'track', 'benchmark', 'train', 'val', 'export'}\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n",
            "        yolo explorer data=data.yaml model=yolov8n.pt\n",
            "    \n",
            "    6. Streamlit real-time webcam inference GUI\n",
            "        yolo streamlit-predict\n",
            "        \n",
            "    7. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Caminho para o arquivo de v√≠deo\n",
        "video_path = \"/content/drive/MyDrive/Videos_Gados/Basal/1h 1059.mp4\"  # Substitua pelo caminho do seu v√≠deo\n",
        "\n",
        "# Carrega o modelo YOLO\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Abre o v√≠deo\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Define a dura√ß√£o da captura em segundos (opcional)\n",
        "duration = 5\n",
        "\n",
        "# Registra o tempo inicial (opcional)\n",
        "start_time = cv2.getTickCount()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Verifica se a dura√ß√£o desejada foi atingida (opcional)\n",
        "    current_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
        "    if current_time > duration:\n",
        "        break\n",
        "\n",
        "    # Realiza a detec√ß√£o de objetos\n",
        "    results = model(frame)\n",
        "\n",
        "    # Desenha as bounding boxes e labels na imagem\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Exibe o frame com as bounding boxes\n",
        "    cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "NmFGJQu0dPmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo model download yolov8n\n",
        "\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Caminho para o arquivo de v√≠deo\n",
        "video_path = \"/content/drive/MyDrive/Videos_Gados/Basal/1677405439482.mp4\"\n",
        "\n",
        "# Carrega o modelo YOLO\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Abre o v√≠deo\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Realiza a detec√ß√£o de objetos com limiar de confian√ßa ajustado\n",
        "    results = model(frame, conf=0.25)\n",
        "\n",
        "    # Desenha as bounding boxes e labels na imagem\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Exibe o frame com as bounding boxes\n",
        "    cv2_imshow(annotated_frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31R6EFUzd0jn",
        "outputId": "69251fef-ec51-4999-dd58-2cdcbb6356b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 755, in entrypoint\n",
            "    raise SyntaxError(\n",
            "SyntaxError: '\u001b[31m\u001b[1mmodel\u001b[0m' is a valid YOLO argument but is missing an '=' sign to set its value, i.e. try 'model=None'\n",
            "\n",
            "    Arguments received: ['yolo', 'model', 'download', 'yolov8n']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of {'pose', 'segment', 'classify', 'detect', 'obb'}\n",
            "                MODE (required) is one of {'train', 'benchmark', 'val', 'predict', 'track', 'export'}\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n",
            "        yolo explorer data=data.yaml model=yolov8n.pt\n",
            "    \n",
            "    6. Streamlit real-time webcam inference GUI\n",
            "        yolo streamlit-predict\n",
            "        \n",
            "    7. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1gTbMsOA3OOFznxg3GSnyHk28vVGf2Q1N",
      "authorship_tag": "ABX9TyPn959svk/o+J/A5vDgIDR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}